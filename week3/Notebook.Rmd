---
title: "Week 3 Notes"
output: html_notebook
---

## Subsetting and Sorting


## Summarizing Data

### Preparing the data

```{r}
if(!file.exists("./data")) {
        dir.create("./data")
    }
    fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
    download.file(fileUrl, destfile="./data/restaurants.csv", method="curl")
    restData <- read.csv("./data/restaurants.csv")
```


### Cross Tabs

```{r}
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
```

We can make cross tabs

```{r}
xt <- xtabs(Freq ~ Gender + Admit, data=DF)
xt
```

### Cross tabs for larger variables or Flattables

```{r}
data(warpbreaks)
warpbreaks$replicate <- rep(1:9, len = 54)
xt = xtabs(breaks~.,data=warpbreaks)
#xt
ftable(xt)
```

### Size of a data set

```{r}
fakeData = rnorm(1e5)
object.size(fakeData)
```
```{r}
print(object.size(fakeData), units="Mb")
```

## Creating New Variables

We will use again the restaurant data set, available in *restData*


### Creat sequences

We can create sequences by setting the step
```{r}
s1 <- seq(1,10, by=2); s1
```

We can also create them by setting the length parameter to the command *seq*

```{r}
s2 <- seq(1,10, length=3); s2
```

And finally we can also create an index vector from a previosyly existing one

```{r}
x <- c(1,3,8,25,100); seq(along=x)
```

This can be used for looping

### Subsetting variables

```{r}
restData$nearMe <- restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
```

### Creating binary variables

In this case we create a new column to store if an entry has a correct zip code or not. We also create a table and compare the result with zipCode <0. As we can see it's all correct.

```{r}
restData$zipWrong <- ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong, restData$zipCode < 0)
```

### Creating categorical variables

We are going to break the data using the cut command into quantiles. Check *?cut* it converts numerics to Factors.

```{r}
restData$zipGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
```

```{r}
table(restData$zipGroups, restData$zipCode)
```

### Easier way to do cutting

We can install the alternative function called *cut2*.
```{r}
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g = 4)
table(restData$zipGroups)
```

### Create Factor variables

```{r}
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
```

```{r}
class(restData$zcf)
```

### Levels of factor variables

```{r}
yesno <- sample(c("yes","no"), size=10,replace=TRUE)
yesnofac <- factor(yesno, levels=c("yes", "no"))
relevel(yesnofac,ref="yes")
```

```{r}
as.numeric(yesnofac)
```

### Cutting creates factor variables

```{r}
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g = 4)
table(restData$zipGroups)
```

### Using the mutate function

The mutate function belongs in the plyr package. 

```{r}
library(Hmisc); library(plyr)
restData2 <-  mutate(restData, zipGroups=cut2(zipCode, g=4))
table(restData2$zipGroups)
```

### Common Transforms

Chekc following links

http://statmethods.net/management/functions.html

http://www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf

http://plyr.had.co.nz/09-user/


## Reshaping Data

The goal is tidy data:

- each variable column
- each observation in a row
- each table/file for one kind of observation

### Start with reshaping

```{r}
library(reshape2)
head(mtcars)
```

### Melting a data set

We are going to use melt and we are going to tell it which are id variables and which are mesaurement variables. So we have a variable column with all the differenet variables.

```{r}
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname", "gear", "cyl"), measure.vars=c("mpg","hp"))
head(carMelt, n = 3)
```


```{r}
tail(carMelt, n=3)
```


### Casting data frames

We were use here the cyliinder as identifier, and then put in the columns the variables.

```{r}
cylData <- dcast(carMelt, cyl ~ variable)
cylData
```

We can also abreviate it by mean of the variables

```{r}
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
```


### Averaging values

```{r}
head(InsectSprays)
```

With tapply, we can do something similar: I apply to count, using the index spray, the function *sum*.

```{r}
tapply(InsectSprays$count, InsectSprays$spray, sum)
```

### Another way - split

```{r}
spIns <- split(InsectSprays$count, InsectSprays$spray)
spIns
```

Then to the split the can apply a function

```{r}
sprCount = lapply(spIns, sum)
sprCount
```

We can go back to a vector, instead of a list

```{r}
unlist(sprCount)
```

Sapply tries to do this automagically
```{r}
sapply(spIns, sum)
```

### Another way - plyr package


ddply uses the variable in brackets *(spray)* to summarize by summing the count in a column called sum.

```{r}
ddply(InsectSprays,.(spray), summarize, sum=sum(count))
```

### Creating a new variable

In some cases we want to have an extra variable to the data set, we can do that by using the following

```{r}
spraySums <- ddply(InsectSprays,.(spray), summarize, sum=ave(count, FUN=sum))
dim(spraySums)
```

```{r}
head(spraySums)
```

### More information

- Tutorial of plyr: http://plyr.had.co.nz/09-user/
- Reshape tutorial: http://www.slideshare.net/jeffreybreen/reshaping-data-in-r
- Goog plyr primer: http://www.r-bloggers.com/a-quick-primer-on-split-apply-combine-problems

- Check also the functions: 
    - acast: casting as multidimensional arrays: 
    - arrange: faster reordering without using order
    - mutate: add new variables

## Managing Data Frames with dplyr - Introduction

### Introduction

dplyr simplies lots of operations in R, while providing a very fast implementation (C++)

Verbs

- select
- filter
- arrange
- rename
- mutate
- summarise / summarize

All the functions  have the following properties:

* First argument is a data frame
* Next argumetns describe the operations to perform on the data frame. Columns don't need to be referred by $
* Result is a new data frame

## Managing Data Frams with dplyr - Basic Tools

```{r}
install.packages("dplyr")
library("dplyr")
```

We load the example data set for mars
```{r}
data(mtcars)
names(mtcars)
```

### Using dplyr:select

We can select specific columns

```{r}
head(select(mtcars, cyl:hp))
```

and exclude them:


```{r}
head(select(mtcars, -(cyl:hp)))
```

### Using dplyr:filter

```{r}
mtcars.f <- filter(mtcars, mpg > 30)
mtcars.f
```

We can also combine the conditions

```{r}
mtcars.f <- filter(mtcars, (hp > 100 & cyl < 6))
mtcars.f
```

### Using dplyr:arrange

Used to reorder the rows of a data frame based on the values of a column.

```{r}
mtcars.r <- arrange(mtcars,hp)
head(mtcars.r)
```

```{r}
mtcars.r <- arrange(mtcars,desc(hp))
head(mtcars.r)
```


### Using dplyr:rename

```{r}
mtcars.r <- rename(mtcars, horsepower = hp, cylinders = cyl)
head(mtcars.r)
```



### Using dplyr:mutate

Create new variable

```{r}
mtcars.m <- mutate(mtcars, hpdetrend = hp-mean(hp, na.rm=TRUE))
head(select(mtcars.m, hp, hpdetrend))
```

We can also create factor variables. Let's do it to see if cars are fast or not depending on their hp.

```{r}
mtcars.m <- mutate(mtcars, fastcat = factor(1 *(hp > 120), labels = c("slow", "fast")))
fastslow <- group_by(mtcars.m, fastcat)
fastslow
```
Now we can summarize and see what is the mean and max for different columns depending on the category:

```{r}
summarize(fastslow, disp = mean(disp), maxmpg = max(mpg), medianqsec = median(qsec))
```


We can also use the pipeline operator to pipe results from one command to another. The dplyr utilities do not need in this case to have the data frame parameter specified

```{r}
mtcars %>% mutate(fastcat = factor(1 *(hp > 120), labels = c("slow", "fast"))) %>% group_by(fastcat) %>% summarize(disp = mean(disp), maxmpg = max(mpg), medianqsec = median(qsec))
```

### Other benefits

* dplyr also works with other data frame backends
* can use data.table for large fast tables
* Also use sql interface via DBI package








